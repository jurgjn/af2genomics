{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index  count  timestamp                name                     utilization.gpu [%]  utilization.memory [%]  memory.total [MiB]  memory.free [MiB]  memory.used [MiB]\n",
      "0      1      2024/08/26 13:57:53.170  NVIDIA GeForce RTX 4090  66                   14                      24564               17689              6527\n",
      "0      1      2024/08/26 13:57:58.176  NVIDIA GeForce RTX 4090  65                   8                       24564               18537              5679\n",
      "0      1      2024/08/26 13:58:03.177  NVIDIA GeForce RTX 4090  71                   29                      24564               17829              6387\n",
      "0      1      2024/08/26 13:58:08.179  NVIDIA GeForce RTX 4090  58                   12                      24564               18905              5311\n",
      "0      1      2024/08/26 13:58:13.180  NVIDIA GeForce RTX 4090  68                   16                      24564               17829              6387\n",
      "0      1      2024/08/26 13:58:18.181  NVIDIA GeForce RTX 4090  67                   27                      24564               17829              6387\n",
      "0      1      2024/08/26 13:58:23.182  NVIDIA GeForce RTX 4090  52                   8                       24564               17825              6391\n",
      "0      1      2024/08/26 13:58:28.184  NVIDIA GeForce RTX 4090  74                   29                      24564               17829              6387\n",
      "0      1      2024/08/26 13:58:33.185  NVIDIA GeForce RTX 4090  56                   9                       24564               17829              6387\n",
      "0      1      2024/08/26 13:58:38.186  NVIDIA GeForce RTX 4090  69                   17                      24564               18907              5309\n",
      "0      1      2024/08/26 13:58:43.187  NVIDIA GeForce RTX 4090  66                   27                      24564               17829              6387\n",
      "0      1      2024/08/26 13:58:48.189  NVIDIA GeForce RTX 4090  65                   15                      24564               18905              5311\n",
      "0      1      2024/08/26 13:58:53.190  NVIDIA GeForce RTX 4090  68                   26                      24564               18169              6047\n",
      "0      1      2024/08/26 13:58:58.192  NVIDIA GeForce RTX 4090  71                   29                      24564               17461              6755\n",
      "0      1      2024/08/26 13:59:03.194  NVIDIA GeForce RTX 4090  74                   29                      24564               17461              6755\n",
      "0      1      2024/08/26 13:59:08.195  NVIDIA GeForce RTX 4090  68                   28                      24564               17461              6755\n"
     ]
    }
   ],
   "source": [
    "# Show/check tabs with: `| cat --show-tabs`\n",
    "# https://unix.stackexchange.com/questions/57222/how-can-i-use-column-to-delimit-on-tabs-and-not-spaces\n",
    "# > I had to do column -t -s $'\\t' as bash seemed to think '\\t' mean both \\  and t, but $'\\t' means a literal tab. Bash stinks\n",
    "# --table-right 1,2,5,6,7,8,9 right-aligns all except last column?\n",
    "cat nvidia-smi.csv \\\n",
    "| sed 's|, |\\t|g' \\\n",
    "| column -t -s $'\\t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index\t count\t timestamp\t name\t utilization.gpu [%]\t utilization.memory [%]\t memory.total [MiB]\t memory.free [MiB]\t memory.used [MiB]\n",
      "0\t 1\t 2024/08/26 13:57:53.170\t NVIDIA GeForce RTX 4090\t 66\t 14\t 24564\t 17689\t 6527\n",
      "0\t 1\t 2024/08/26 13:57:58.176\t NVIDIA GeForce RTX 4090\t 65\t 8\t 24564\t 18537\t 5679\n",
      "0\t 1\t 2024/08/26 13:58:03.177\t NVIDIA GeForce RTX 4090\t 71\t 29\t 24564\t 17829\t 6387\n",
      "0\t 1\t 2024/08/26 13:58:08.179\t NVIDIA GeForce RTX 4090\t 58\t 12\t 24564\t 18905\t 5311\n",
      "0\t 1\t 2024/08/26 13:58:13.180\t NVIDIA GeForce RTX 4090\t 68\t 16\t 24564\t 17829\t 6387\n",
      "0\t 1\t 2024/08/26 13:58:23.182\t NVIDIA GeForce RTX 4090\t 52\t 8\t 24564\t 17825\t 6391\n",
      "0\t 1\t 2024/08/26 13:58:28.184\t NVIDIA GeForce RTX 4090\t 74\t 29\t 24564\t 17829\t 6387\n",
      "0\t 1\t 2024/08/26 13:58:38.186\t NVIDIA GeForce RTX 4090\t 69\t 17\t 24564\t 18907\t 5309\n",
      "0\t 1\t 2024/08/26 13:58:43.187\t NVIDIA GeForce RTX 4090\t 66\t 27\t 24564\t 17829\t 6387\n",
      "0\t 1\t 2024/08/26 13:58:48.189\t NVIDIA GeForce RTX 4090\t 65\t 15\t 24564\t 18905\t 5311\n",
      "0\t 1\t 2024/08/26 13:58:53.190\t NVIDIA GeForce RTX 4090\t 68\t 26\t 24564\t 18169\t 6047\n",
      "0\t 1\t 2024/08/26 13:58:58.192\t NVIDIA GeForce RTX 4090\t 71\t 29\t 24564\t 17461\t 6755\n"
     ]
    }
   ],
   "source": [
    "# Print only if $9 (GPU mem usage) changes compared to previous line\n",
    "cat nvidia-smi.csv | awk -F',' -v OFS='\\t' '{if ($9!=prev9) {$1=$1; print;} prev9=$9}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA System Management Interface -- v535.183.01\n",
      "\n",
      "NVSMI provides monitoring information for Tesla and select Quadro devices.\n",
      "The data is presented in either a plain text or an XML format, via stdout or a file.\n",
      "NVSMI also provides several management operations for changing the device state.\n",
      "\n",
      "Note that the functionality of NVSMI is exposed through the NVML C-based\n",
      "library. See the NVIDIA developer website for more information about NVML.\n",
      "Python wrappers to NVML are also available.  The output of NVSMI is\n",
      "not guaranteed to be backwards compatible; NVML and the bindings are backwards\n",
      "compatible.\n",
      "\n",
      "http://developer.nvidia.com/nvidia-management-library-nvml/\n",
      "http://pypi.python.org/pypi/nvidia-ml-py/\n",
      "Supported products:\n",
      "- Full Support\n",
      "    - All Tesla products, starting with the Kepler architecture\n",
      "    - All Quadro products, starting with the Kepler architecture\n",
      "    - All GRID products, starting with the Kepler architecture\n",
      "    - GeForce Titan products, starting with the Kepler architecture\n",
      "- Limited Support\n",
      "    - All Geforce products, starting with the Kepler architecture\n",
      "nvidia-smi [OPTION1 [ARG1]] [OPTION2 [ARG2]] ...\n",
      "\n",
      "    -h,   --help                Print usage information and exit.\n",
      "\n",
      "  LIST OPTIONS:\n",
      "\n",
      "    -L,   --list-gpus           Display a list of GPUs connected to the system.\n",
      "\n",
      "    -B,   --list-excluded-gpus  Display a list of excluded GPUs in the system.\n",
      "\n",
      "  SUMMARY OPTIONS:\n",
      "\n",
      "    <no arguments>              Show a summary of GPUs connected to the system.\n",
      "\n",
      "    [plus any of]\n",
      "\n",
      "    -i,   --id=                 Target a specific GPU.\n",
      "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
      "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\n",
      "\n",
      "  QUERY OPTIONS:\n",
      "\n",
      "    -q,   --query               Display GPU or Unit info.\n",
      "\n",
      "    [plus any of]\n",
      "\n",
      "    -u,   --unit                Show unit, rather than GPU, attributes.\n",
      "    -i,   --id=                 Target a specific GPU or Unit.\n",
      "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
      "    -x,   --xml-format          Produce XML output.\n",
      "          --dtd                 When showing xml output, embed DTD.\n",
      "    -d,   --display=            Display only selected information: MEMORY,\n",
      "                                    UTILIZATION, ECC, TEMPERATURE, POWER, CLOCK,\n",
      "                                    COMPUTE, PIDS, PERFORMANCE, SUPPORTED_CLOCKS,\n",
      "                                    PAGE_RETIREMENT, ACCOUNTING, ENCODER_STATS,\n",
      "                                    SUPPORTED_GPU_TARGET_TEMP, VOLTAGE\n",
      "                                    FBC_STATS, ROW_REMAPPER, RESET_STATUS\n",
      "                                Flags can be combined with comma e.g. ECC,POWER.\n",
      "                                Sampling data with max/min/avg is also returned \n",
      "                                for POWER, UTILIZATION and CLOCK display types.\n",
      "                                Doesn't work with -u or -x flags.\n",
      "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\n",
      "\n",
      "    -lms, --loop-ms=            Probe until Ctrl+C at specified millisecond interval.\n",
      "\n",
      "  SELECTIVE QUERY OPTIONS:\n",
      "\n",
      "    Allows the caller to pass an explicit list of properties to query.\n",
      "\n",
      "    [one of]\n",
      "\n",
      "    --query-gpu                 Information about GPU.\n",
      "                                Call --help-query-gpu for more info.\n",
      "    --query-supported-clocks    List of supported clocks.\n",
      "                                Call --help-query-supported-clocks for more info.\n",
      "    --query-compute-apps        List of currently active compute processes.\n",
      "                                Call --help-query-compute-apps for more info.\n",
      "    --query-accounted-apps      List of accounted compute processes.\n",
      "                                Call --help-query-accounted-apps for more info.\n",
      "                                This query is not supported on vGPU host.\n",
      "    --query-retired-pages       List of device memory pages that have been retired.\n",
      "                                Call --help-query-retired-pages for more info.\n",
      "    --query-remapped-rows       Information about remapped rows.\n",
      "                                Call --help-query-remapped-rows for more info.\n",
      "\n",
      "    [mandatory]\n",
      "\n",
      "    --format=                   Comma separated list of format options:\n",
      "                                  csv - comma separated values (MANDATORY)\n",
      "                                  noheader - skip the first line with column headers\n",
      "                                  nounits - don't print units for numerical\n",
      "                                             values\n",
      "\n",
      "    [plus any of]\n",
      "\n",
      "    -i,   --id=                 Target a specific GPU or Unit.\n",
      "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
      "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\n",
      "    -lms, --loop-ms=            Probe until Ctrl+C at specified millisecond interval.\n",
      "\n",
      "  DEVICE MODIFICATION OPTIONS:\n",
      "\n",
      "    [any one of]\n",
      "\n",
      "    -pm,  --persistence-mode=   Set persistence mode: 0/DISABLED, 1/ENABLED\n",
      "    -e,   --ecc-config=         Toggle ECC support: 0/DISABLED, 1/ENABLED\n",
      "    -p,   --reset-ecc-errors=   Reset ECC error counts: 0/VOLATILE, 1/AGGREGATE\n",
      "    -c,   --compute-mode=       Set MODE for compute applications:\n",
      "                                0/DEFAULT, 1/EXCLUSIVE_THREAD (DEPRECATED),\n",
      "                                2/PROHIBITED, 3/EXCLUSIVE_PROCESS\n",
      "          --gom=                Set GPU Operation Mode:\n",
      "                                    0/ALL_ON, 1/COMPUTE, 2/LOW_DP\n",
      "    -r    --gpu-reset           Trigger reset of the GPU.\n",
      "                                Can be used to reset the GPU HW state in situations\n",
      "                                that would otherwise require a machine reboot.\n",
      "                                Typically useful if a double bit ECC error has\n",
      "                                occurred.\n",
      "                                Reset operations are not guarenteed to work in\n",
      "                                all cases and should be used with caution.\n",
      "    -vm   --virt-mode=          Switch GPU Virtualization Mode:\n",
      "                                Sets GPU virtualization mode to 3/VGPU or 4/VSGA\n",
      "                                Virtualization mode of a GPU can only be set when\n",
      "                                it is running on a hypervisor.\n",
      "    -lgc  --lock-gpu-clocks=    Specifies <minGpuClock,maxGpuClock> clocks as a\n",
      "                                    pair (e.g. 1500,1500) that defines the range \n",
      "                                    of desired locked GPU clock speed in MHz.\n",
      "                                    Setting this will supercede application clocks\n",
      "                                    and take effect regardless if an app is running.\n",
      "                                    Input can also be a singular desired clock value\n",
      "                                    (e.g. <GpuClockValue>). Optionally, --mode can be\n",
      "                                    specified to indicate a special mode.\n",
      "    -m    --mode=               Specifies the mode for --locked-gpu-clocks.\n",
      "                                    Valid modes: 0, 1\n",
      "    -rgc  --reset-gpu-clocks\n",
      "                                Resets the Gpu clocks to the default values.\n",
      "    -lmc  --lock-memory-clocks=  Specifies <minMemClock,maxMemClock> clocks as a\n",
      "                                    pair (e.g. 5100,5100) that defines the range \n",
      "                                    of desired locked Memory clock speed in MHz.\n",
      "                                    Input can also be a singular desired clock value\n",
      "                                    (e.g. <MemClockValue>).\n",
      "    -rmc  --reset-memory-clocks\n",
      "                                Resets the Memory clocks to the default values.\n",
      "    -lmcd --lock-memory-clocks-deferred=\n",
      "                                    Specifies memClock clock to lock. This limit is\n",
      "                                    applied the next time GPU is initialized.\n",
      "                                    This is guaranteed by unloading and reloading the kernel module.\n",
      "                                    Requires root.\n",
      "    -rmcd --reset-memory-clocks-deferred\n",
      "                                Resets the deferred Memory clocks applied.\n",
      "    -ac   --applications-clocks= Specifies <memory,graphics> clocks as a\n",
      "                                    pair (e.g. 2000,800) that defines GPU's\n",
      "                                    speed in MHz while running applications on a GPU.\n",
      "    -rac  --reset-applications-clocks\n",
      "                                Resets the applications clocks to the default values.\n",
      "    -pl   --power-limit=        Specifies maximum power management limit in watts.\n",
      "                                Takes an optional argument --scope.\n",
      "    -sc   --scope=              Specifies the device type for --scope: 0/GPU, 1/TOTAL_MODULE (Grace Hopper Only)\n",
      "    -cc   --cuda-clocks=        Overrides or restores default CUDA clocks.\n",
      "                                In override mode, GPU clocks higher frequencies when running CUDA applications.\n",
      "                                Only on supported devices starting from the Volta series.\n",
      "                                Requires administrator privileges.\n",
      "                                0/RESTORE_DEFAULT, 1/OVERRIDE\n",
      "    -am   --accounting-mode=    Enable or disable Accounting Mode: 0/DISABLED, 1/ENABLED\n",
      "    -caa  --clear-accounted-apps\n",
      "                                Clears all the accounted PIDs in the buffer.\n",
      "          --auto-boost-default= Set the default auto boost policy to 0/DISABLED\n",
      "                                or 1/ENABLED, enforcing the change only after the\n",
      "                                last boost client has exited.\n",
      "          --auto-boost-permission=\n",
      "                                Allow non-admin/root control over auto boost mode:\n",
      "                                0/UNRESTRICTED, 1/RESTRICTED\n",
      "    -mig  --multi-instance-gpu= Enable or disable Multi Instance GPU: 0/DISABLED, 1/ENABLED\n",
      "                                Requires root.\n",
      "    -gtt  --gpu-target-temp=    Set GPU Target Temperature for a GPU in degree celsius.\n",
      "                                Requires administrator privileges\n",
      "\n",
      "   [plus optional]\n",
      "\n",
      "    -i,   --id=                 Target a specific GPU.\n",
      "    -eow, --error-on-warning    Return a non-zero error for warnings.\n",
      "\n",
      "  UNIT MODIFICATION OPTIONS:\n",
      "\n",
      "    -t,   --toggle-led=         Set Unit LED state: 0/GREEN, 1/AMBER\n",
      "\n",
      "   [plus optional]\n",
      "\n",
      "    -i,   --id=                 Target a specific Unit.\n",
      "\n",
      "  SHOW DTD OPTIONS:\n",
      "\n",
      "          --dtd                 Print device DTD and exit.\n",
      "\n",
      "     [plus optional]\n",
      "\n",
      "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
      "    -u,   --unit                Show unit, rather than device, DTD.\n",
      "\n",
      "    --debug=                    Log encrypted debug information to a specified file. \n",
      "\n",
      " Device Monitoring:\n",
      "    dmon                        Displays device stats in scrolling format.\n",
      "                                \"nvidia-smi dmon -h\" for more information.\n",
      "\n",
      "    daemon                      Runs in background and monitor devices as a daemon process.\n",
      "                                This is an experimental feature. Not supported on Windows baremetal\n",
      "                                \"nvidia-smi daemon -h\" for more information.\n",
      "\n",
      "    replay                      Used to replay/extract the persistent stats generated by daemon.\n",
      "                                This is an experimental feature.\n",
      "                                \"nvidia-smi replay -h\" for more information.\n",
      "\n",
      " Process Monitoring:\n",
      "    pmon                        Displays process stats in scrolling format.\n",
      "                                \"nvidia-smi pmon -h\" for more information.\n",
      "\n",
      " TOPOLOGY:\n",
      "    topo                        Displays device/system topology. \"nvidia-smi topo -h\" for more information.\n",
      "\n",
      " DRAIN STATES:\n",
      "    drain                       Displays/modifies GPU drain states for power idling. \"nvidia-smi drain -h\" for more information.\n",
      "\n",
      " NVLINK:\n",
      "    nvlink                      Displays device nvlink information. \"nvidia-smi nvlink -h\" for more information.\n",
      "\n",
      " C2C:\n",
      "    c2c                         Displays device C2C information. \"nvidia-smi c2c -h\" for more information.\n",
      "\n",
      " CLOCKS:\n",
      "    clocks                      Control and query clock information. \"nvidia-smi clocks -h\" for more information.\n",
      "\n",
      " ENCODER SESSIONS:\n",
      "    encodersessions             Displays device encoder sessions information. \"nvidia-smi encodersessions -h\" for more information.\n",
      "\n",
      " FBC SESSIONS:\n",
      "    fbcsessions                 Displays device FBC sessions information. \"nvidia-smi fbcsessions -h\" for more information.\n",
      "\n",
      " GRID vGPU:\n",
      "    vgpu                        Displays vGPU information. \"nvidia-smi vgpu -h\" for more information.\n",
      "\n",
      " MIG:\n",
      "    mig                         Provides controls for MIG management. \"nvidia-smi mig -h\" for more information.\n",
      "\n",
      " COMPUTE POLICY:\n",
      "    compute-policy              Control and query compute policies. \"nvidia-smi compute-policy -h\" for more information. \n",
      "\n",
      " BOOST SLIDER:\n",
      "    boost-slider                Control and query boost sliders. \"nvidia-smi boost-slider -h\" for more information. \n",
      "\n",
      " POWER HINT:    power-hint                  Estimates GPU power usage. \"nvidia-smi power-hint -h\" for more information. \n",
      "\n",
      " BASE CLOCKS:    base-clocks                 Query GPU base clocks. \"nvidia-smi base-clocks -h\" for more information. \n",
      "\n",
      " CONFIDENTIAL COMPUTE:\n",
      "    conf-compute                Control and query confidential compute. \"nvidia-smi conf-compute -h\" for more information. \n",
      "\n",
      " GPU PERFORMANCE MONITORING: \n",
      "    gpm                         Control and query GPU performance monitoring unit. \"nvidia-smi gpm -h\" for more information. \n",
      "\n",
      "Please see the nvidia-smi(1) manual page for more detailed information.\n"
     ]
    }
   ],
   "source": [
    "nvidia-smi -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 4090 (UUID: GPU-8d69cbaf-5625-e641-e7cc-27a5117b3cf4)\n"
     ]
    }
   ],
   "source": [
    "nvidia-smi --list-gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============NVSMI LOG==============\n",
      "\n",
      "Timestamp                                 : Wed Jul 31 10:32:15 2024\n",
      "Driver Version                            : 535.183.01\n",
      "CUDA Version                              : 12.2\n",
      "\n",
      "Attached GPUs                             : 1\n",
      "GPU 00000000:C1:00.0\n",
      "    FB Memory Usage\n",
      "        Total                             : 24564 MiB\n",
      "        Reserved                          : 346 MiB\n",
      "        Used                              : 1 MiB\n",
      "        Free                              : 24216 MiB\n",
      "    BAR1 Memory Usage\n",
      "        Total                             : 256 MiB\n",
      "        Used                              : 2 MiB\n",
      "        Free                              : 254 MiB\n",
      "    Conf Compute Protected Memory Usage\n",
      "        Total                             : 0 MiB\n",
      "        Used                              : 0 MiB\n",
      "        Free                              : 0 MiB\n",
      "    Utilization\n",
      "        Gpu                               : 0 %\n",
      "        Memory                            : 0 %\n",
      "        Encoder                           : 0 %\n",
      "        Decoder                           : 0 %\n",
      "        JPEG                              : 0 %\n",
      "        OFA                               : 0 %\n",
      "    GPU Utilization Samples\n",
      "        Duration                          : 14.00 sec\n",
      "        Number of Samples                 : 71\n",
      "        Max                               : 0 %\n",
      "        Min                               : 0 %\n",
      "        Avg                               : 0 %\n",
      "    Memory Utilization Samples\n",
      "        Duration                          : 14.00 sec\n",
      "        Number of Samples                 : 71\n",
      "        Max                               : 0 %\n",
      "        Min                               : 0 %\n",
      "        Avg                               : 0 %\n",
      "    ENC Utilization Samples\n",
      "        Duration                          : 14.00 sec\n",
      "        Number of Samples                 : 71\n",
      "        Max                               : 0 %\n",
      "        Min                               : 0 %\n",
      "        Avg                               : 0 %\n",
      "    DEC Utilization Samples\n",
      "        Duration                          : 14.00 sec\n",
      "        Number of Samples                 : 71\n",
      "        Max                               : 0 %\n",
      "        Min                               : 0 %\n",
      "        Avg                               : 0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nvidia-smi --query --id=0 --display=MEMORY,UTILIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of valid properties to query for the switch \"--query-gpu\":\n",
      "\n",
      "\"timestamp\"\n",
      "The timestamp of when the query was made in format \"YYYY/MM/DD HH:MM:SS.msec\".\n",
      "\n",
      "\"driver_version\"\n",
      "The version of the installed NVIDIA display driver. This is an alphanumeric string.\n",
      "\n",
      "Section about vgpu_driver_capability properties\n",
      "Retrieves information about driver level caps.\n",
      "\n",
      "\"vgpu_driver_capability.heterogenous_multivGPU\"\n",
      "Whether heterogeneuos multi-vGPU is supported by driver.\n",
      "\n",
      "\"count\"\n",
      "The number of NVIDIA GPUs in the system.\n",
      "\n",
      "\"name\" or \"gpu_name\"\n",
      "The official product name of the GPU. This is an alphanumeric string. For all products.\n",
      "\n",
      "\"serial\" or \"gpu_serial\"\n",
      "This number matches the serial number physically printed on each board. It is a globally unique immutable alphanumeric value.\n",
      "\n",
      "\"uuid\" or \"gpu_uuid\"\n",
      "This value is the globally unique immutable alphanumeric identifier of the GPU. It does not correspond to any physical label on the board.\n",
      "\n",
      "\"pci.bus_id\" or \"gpu_bus_id\"\n",
      "PCI bus id as \"domain:bus:device.function\", in hex.\n",
      "\n",
      "\"pci.domain\"\n",
      "PCI domain number, in hex.\n",
      "\n",
      "\"pci.bus\"\n",
      "PCI bus number, in hex.\n",
      "\n",
      "\"pci.device\"\n",
      "PCI device number, in hex.\n",
      "\n",
      "\"pci.device_id\"\n",
      "PCI vendor device id, in hex\n",
      "\n",
      "\"pci.sub_device_id\"\n",
      "PCI Sub System id, in hex\n",
      "\n",
      "Section about vgpu_device_capability properties\n",
      "Retrieves information about device level caps.\n",
      "\n",
      "\"vgpu_device_capability.fractional_multiVgpu\"\n",
      "Fractional vGPU profiles on this GPU can be used in multi-vGPU configurations.\n",
      "\n",
      "\"vgpu_device_capability.heterogeneous_timeSlice_profile\"\n",
      "Supports concurrent execution of timesliced vGPU profiles of differing types.\n",
      "\n",
      "\"vgpu_device_capability.heterogeneous_timeSlice_sizes\"\n",
      "Supports concurrent execution of timesliced vGPU profiles of differing framebuffer sizes.\n",
      "\n",
      "\"pcie.link.gen.current\"\n",
      "The current PCI-E link generation. These may be reduced when the GPU is not in use. Deprecated, use pcie.link.gen.gpucurrent instead.\n",
      "\n",
      "\"pcie.link.gen.gpucurrent\"\n",
      "The current PCI-E link generation. These may be reduced when the GPU is not in use.\n",
      "\n",
      "\"pcie.link.gen.max\"\n",
      "The maximum PCI-E link generation possible with this GPU and system configuration. For example, if the GPU supports a higher PCIe generation than the system supports then this reports the system PCIe generation.\n",
      "\n",
      "\"pcie.link.gen.gpumax\"\n",
      "The maximum PCI-E link generation supported by this GPU.\n",
      "\n",
      "\"pcie.link.gen.hostmax\"\n",
      "The maximum PCI-E link generation supported by the root port corresponding to this GPU.\n",
      "\n",
      "\"pcie.link.width.current\"\n",
      "The current PCI-E link width. These may be reduced when the GPU is not in use.\n",
      "\n",
      "\"pcie.link.width.max\"\n",
      "The maximum PCI-E link width possible with this GPU and system configuration. For example, if the GPU supports a higher PCIe generation than the system supports then this reports the system PCIe generation.\n",
      "\n",
      "\"index\"\n",
      "Zero based index of the GPU. Can change at each boot.\n",
      "\n",
      "\"display_mode\"\n",
      "A flag that indicates whether a physical display (e.g. monitor) is currently connected to any of the GPU's connectors. \"Enabled\" indicates an attached display. \"Disabled\" indicates otherwise.\n",
      "\n",
      "\"display_active\"\n",
      "A flag that indicates whether a display is initialized on the GPU's (e.g. memory is allocated on the device for display). Display can be active even when no monitor is physically attached. \"Enabled\" indicates an active display. \"Disabled\" indicates otherwise.\n",
      "\n",
      "\"persistence_mode\"\n",
      "A flag that indicates whether persistence mode is enabled for the GPU. Value is either \"Enabled\" or \"Disabled\". When persistence mode is enabled the NVIDIA driver remains loaded even when no active clients, such as X11 or nvidia-smi, exist. This minimizes the driver load latency associated with running dependent apps, such as CUDA programs. Linux only.\n",
      "\n",
      "\"addressing_mode\"\n",
      "A flag that indicates the type of addressing mode enabled for the GPU. Value is either \"HMM\" or \"ATS\" or \"None\". When the mode is HMM, system allocated memory (malloc, mmap) is addressable from the device (GPU), via software-based mirroring of the CPU's page tables, on the GPU. When the mode is ATS, system allocated memory (malloc, mmap) is addressable from the device (GPU), via Address Translation Services. This means that there is (effectively) a single set of page tables, and the CPU and GPU both use them. The mode is None when neither HMM nor ATS is active. Linux only.\n",
      "\n",
      "\"accounting.mode\"\n",
      "A flag that indicates whether accounting mode is enabled for the GPU. Value is either \"Enabled\" or \"Disabled\". When accounting is enabled statistics are calculated for each compute process running on the GPU.Statistics can be queried during the lifetime or after termination of the process.The execution time of process is reported as 0 while the process is in running state and updated to actualexecution time after the process has terminated. See --help-query-accounted-apps for more info.\n",
      "\n",
      "\"accounting.buffer_size\"\n",
      "The size of the circular buffer that holds list of processes that can be queried for accounting stats. This is the maximum number of processes that accounting information will be stored for before information about oldest processes will get overwritten by information about new processes.\n",
      "\n",
      "Section about driver_model properties\n",
      "On Windows, the TCC and WDDM driver models are supported. The driver model can be changed with the (-dm) or (-fdm) flags. The TCC driver model is optimized for compute applications. I.E. kernel launch times will be quicker with TCC. The WDDM driver model is designed for graphics applications and is not recommended for compute applications. Linux does not support multiple driver models, and will always have the value of \"N/A\". Only for selected products. Please see feature matrix in NVML documentation.\n",
      "\n",
      "\"driver_model.current\"\n",
      "The driver model currently in use. Always \"N/A\" on Linux.\n",
      "\n",
      "\"driver_model.pending\"\n",
      "The driver model that will be used on the next reboot. Always \"N/A\" on Linux.\n",
      "\n",
      "\"vbios_version\"\n",
      "The BIOS of the GPU board.\n",
      "\n",
      "Section about inforom properties\n",
      "Version numbers for each object in the GPU board's inforom storage. The inforom is a small, persistent store of configuration and state data for the GPU. All inforom version fields are numerical. It can be useful to know these version numbers because some GPU features are only available with inforoms of a certain version or higher.\n",
      "\n",
      "\"inforom.img\" or \"inforom.image\"\n",
      "Global version of the infoROM image. Image version just like VBIOS version uniquely describes the exact version of the infoROM flashed on the board in contrast to infoROM object version which is only an indicator of supported features.\n",
      "\n",
      "\"inforom.oem\"\n",
      "Version for the OEM configuration data.\n",
      "\n",
      "\"inforom.ecc\"\n",
      "Version for the ECC recording data.\n",
      "\n",
      "\"inforom.pwr\" or \"inforom.power\"\n",
      "Version for the power management data.\n",
      "\n",
      "Section about reset_status properties\n",
      "GPU reset status information. Reports if there is a GPU reset required or drain and reset recommended to recover from a bad state. 'N/A' indicates that the field is not supported on the current device or device configuration. An error message indicates that retrieving the field failed.\n",
      "\n",
      "\"reset_status.reset_required\"\n",
      "Checks if a GPU reset is required.\n",
      "\n",
      "\"reset_status.drain_and_reset_recommended\"\n",
      "Checks if a GPU drain and reset is recommended.\n",
      "\n",
      "Section about gom properties\n",
      "GOM allows to reduce power usage and optimize GPU throughput by disabling GPU features. Each GOM is designed to meet specific user needs.\n",
      "In \"All On\" mode everything is enabled and running at full speed.\n",
      "The \"Compute\" mode is designed for running only compute tasks. Graphics operations are not allowed.\n",
      "The \"Low Double Precision\" mode is designed for running graphics applications that don't require high bandwidth double precision.\n",
      "GOM can be changed with the (--gom) flag.\n",
      "\n",
      "\"gom.current\" or \"gpu_operation_mode.current\"\n",
      "The GOM currently in use.\n",
      "\n",
      "\"gom.pending\" or \"gpu_operation_mode.pending\"\n",
      "The GOM that will be used on the next reboot.\n",
      "\n",
      "\"fan.speed\"\n",
      "The fan speed value is the percent of the product's maximum noise tolerance fan speed that the device's fan is currently intended to run at. This value may exceed 100% in certain cases. Note: The reported speed is the intended fan speed. If the fan is physically blocked and unable to spin, this output will not match the actual fan speed. Many parts do not report fan speeds because they rely on cooling via fans in the surrounding enclosure.\n",
      "\n",
      "\"pstate\"\n",
      "The current performance state for the GPU. States range from P0 (maximum performance) to P12 (minimum performance).\n",
      "\n",
      "Section about clocks_event_reasons properties\n",
      "Retrieves information about factors that are reducing the frequency of clocks. If all event reasons are returned as \"Not Active\" it means that clocks are running as high as possible.\n",
      "\n",
      "\"clocks_event_reasons.supported\" or \"clocks_throttle_reasons.supported\"\n",
      "Bitmask of supported clock event reasons. See nvml.h for more details.\n",
      "\n",
      "\"clocks_event_reasons.active\" or \"clocks_throttle_reasons.active\"\n",
      "Bitmask of active clock event reasons. See nvml.h for more details.\n",
      "\n",
      "\"clocks_event_reasons.gpu_idle\" or \"clocks_throttle_reasons.gpu_idle\"\n",
      "Nothing is running on the GPU and the clocks are dropping to Idle state. This limiter may be removed in a later release.\n",
      "\n",
      "\"clocks_event_reasons.applications_clocks_setting\" or \"clocks_throttle_reasons.applications_clocks_setting\"\n",
      "GPU clocks are limited by applications clocks setting. E.g. can be changed by nvidia-smi --applications-clocks=\n",
      "\n",
      "\"clocks_event_reasons.sw_power_cap\" or \"clocks_throttle_reasons.sw_power_cap\"\n",
      "SW Power Scaling algorithm is reducing the clocks below requested clocks because the GPU is consuming too much power. E.g. SW power cap limit can be changed with nvidia-smi --power-limit=\n",
      "\n",
      "\"clocks_event_reasons.hw_slowdown\" or \"clocks_throttle_reasons.hw_slowdown\"\n",
      "HW Slowdown (reducing the core clocks by a factor of 2 or more) is engaged. This is an indicator of:\n",
      " HW Thermal Slowdown: temperature being too high\n",
      " HW Power Brake Slowdown: External Power Brake Assertion is triggered (e.g. by the system power supply)\n",
      " * Power draw is too high and Fast Trigger protection is reducing the clocks\n",
      " * May be also reported during PState or clock change\n",
      " * This behavior may be removed in a later release\n",
      "\n",
      "\"clocks_event_reasons.hw_thermal_slowdown\" or \"clocks_throttle_reasons.hw_thermal_slowdown\"\n",
      "HW Thermal Slowdown (reducing the core clocks by a factor of 2 or more) is engaged. This is an indicator of temperature being too high\n",
      "\n",
      "\"clocks_event_reasons.hw_power_brake_slowdown\" or \"clocks_throttle_reasons.hw_power_brake_slowdown\"\n",
      "HW Power Brake Slowdown (reducing the core clocks by a factor of 2 or more) is engaged. This is an indicator of External Power Brake Assertion being triggered (e.g. by the system power supply)\n",
      "\n",
      "\"clocks_event_reasons.sw_thermal_slowdown\" or \"clocks_throttle_reasons.sw_thermal_slowdown\"\n",
      "SW Thermal capping algorithm is reducing clocks below requested clocks because GPU temperature is higher than Max Operating Temp.\n",
      "\n",
      "\"clocks_event_reasons.sync_boost\" or \"clocks_throttle_reasons.sync_boost\"\n",
      "Sync Boost This GPU has been added to a Sync boost group with nvidia-smi or DCGM in\n",
      " * order to maximize performance per watt. All GPUs in the sync boost group\n",
      " * will boost to the minimum possible clocks across the entire group. Look at\n",
      " * the event reasons for other GPUs in the system to see why those GPUs are\n",
      " * holding this one at lower clocks.\n",
      "\n",
      "Section about memory properties\n",
      "On-board memory information. Reported total memory is affected by ECC state. If ECC is enabled the total available memory is decreased by several percent, due to the requisite parity bits. The driver may also reserve a small amount of memory for internal use, even without active work on the GPU.\n",
      "\n",
      "\"memory.total\"\n",
      "Total installed GPU memory.\n",
      "\n",
      "\"memory.reserved\"\n",
      "Total memory reserved by the NVIDIA driver and firmware.\n",
      "\n",
      "\"memory.used\"\n",
      "Total memory allocated by active contexts.\n",
      "\n",
      "\"memory.free\"\n",
      "Total free memory.\n",
      "\n",
      "\"compute_mode\"\n",
      "The compute mode flag indicates whether individual or multiple compute applications may run on the GPU.\n",
      "\"0: Default\" means multiple contexts are allowed per device.\n",
      "\"1: Exclusive_Thread\", deprecated, use Exclusive_Process instead\n",
      "\"2: Prohibited\" means no contexts are allowed per device (no compute apps).\n",
      "\"3: Exclusive_Process\" means only one context is allowed per device, usable from multiple threads at a time.\n",
      "\n",
      "\"compute_cap\"\n",
      "The CUDA Compute Capability, represented as Major DOT Minor.\n",
      "\n",
      "Section about utilization properties\n",
      "Utilization rates report how busy each GPU is over time, and can be used to determine how much an application is using the GPUs in the system.\n",
      "Note: On MIG-enabled GPUs, querying the utilization of encoder, decoder, jpeg, ofa, gpu, and memory is not currently supported.\n",
      "\n",
      "\"utilization.gpu\"\n",
      "Percent of time over the past sample period during which one or more kernels was executing on the GPU.\n",
      "The sample period may be between 1 second and 1/6 second depending on the product.\n",
      "\n",
      "\"utilization.memory\"\n",
      "Percent of time over the past sample period during which global (device) memory was being read or written.\n",
      "The sample period may be between 1 second and 1/6 second depending on the product.\n",
      "\n",
      "\"utilization.encoder\"\n",
      "Percent of time over the past sample period during which one or more kernels was executing on the Encoder Engine.\n",
      "The sample period may be between 1 second and 1/6 second depending on the product.\n",
      "\n",
      "\"utilization.decoder\"\n",
      "Percent of time over the past sample period during which one or more kernels was executing on the Decoder Engine.\n",
      "The sample period may be between 1 second and 1/6 second depending on the product.\n",
      "\n",
      "\"utilization.jpeg\"\n",
      "Percent of time over the past sample period during which one or more kernels was executing on the Jpeg Engine.\n",
      "The sample period may be between 1 second and 1/6 second depending on the product.\n",
      "\n",
      "\"utilization.ofa\"\n",
      "Percent of time over the past sample period during which one or more kernels was executing on the Optical Flow Accelerator Engine.\n",
      "The sample period may be between 1 second and 1/6 second depending on the product.\n",
      "\n",
      "Section about encoder.stats properties\n",
      "Encoder stats report number of encoder sessions, average FPS and average latency in us for given GPUs in the system.\n",
      "\n",
      "\"encoder.stats.sessionCount\"\n",
      "Number of encoder sessions running on the GPU.\n",
      "\n",
      "\"encoder.stats.averageFps\"\n",
      "Average FPS of all sessions running on the GPU.\n",
      "\n",
      "\"encoder.stats.averageLatency\"\n",
      "Average latency in microseconds of all sessions running on the GPU.\n",
      "\n",
      "Section about ecc.mode properties\n",
      "A flag that indicates whether ECC support is enabled. May be either \"Enabled\" or \"Disabled\". Changes to ECC mode require a reboot. Requires Inforom ECC object version 1.0 or higher.\n",
      "\n",
      "\"ecc.mode.current\"\n",
      "The ECC mode that the GPU is currently operating under.\n",
      "\n",
      "\"ecc.mode.pending\"\n",
      "The ECC mode that the GPU will operate under after the next reboot.\n",
      "\n",
      "Section about ecc.errors properties\n",
      "NVIDIA GPUs can provide error counts for various types of ECC errors. Some ECC errors are either single or double bit, where single bit errors are corrected and double bit errors are uncorrectable. Texture memory errors may be correctable via resend or uncorrectable if the resend fails. These errors are available across two timescales (volatile and aggregate). Single bit ECC errors are automatically corrected by the HW and do not result in data corruption. Double bit errors are detected but not corrected. Please see the ECC documents on the web for information on compute application behavior when double bit errors occur. Volatile error counters track the number of errors detected since the last driver load. Aggregate error counts persist indefinitely and thus act as a lifetime counter.\n",
      "\n",
      "\"ecc.errors.corrected.volatile.device_memory\"\n",
      "Errors detected in global device memory.\n",
      "\n",
      "\"ecc.errors.corrected.volatile.dram\"\n",
      "Errors detected in global device memory.\n",
      "\n",
      "\"ecc.errors.corrected.volatile.register_file\"\n",
      "Errors detected in register file memory.\n",
      "\n",
      "\"ecc.errors.corrected.volatile.l1_cache\"\n",
      "Errors detected in the L1 cache.\n",
      "\n",
      "\"ecc.errors.corrected.volatile.l2_cache\"\n",
      "Errors detected in the L2 cache.\n",
      "\n",
      "\"ecc.errors.corrected.volatile.texture_memory\"\n",
      "Parity errors detected in texture memory.\n",
      "\n",
      "\"ecc.errors.corrected.volatile.cbu\"\n",
      "Parity errors detected in CBU.\n",
      "\n",
      "\"ecc.errors.corrected.volatile.sram\"\n",
      "Errors detected in global SRAMs.\n",
      "\n",
      "\"ecc.errors.corrected.volatile.total\"\n",
      "Total errors detected across entire chip.\n",
      "\n",
      "\"ecc.errors.corrected.aggregate.device_memory\"\n",
      "Errors detected in global device memory.\n",
      "\n",
      "\"ecc.errors.corrected.aggregate.dram\"\n",
      "Errors detected in global device memory.\n",
      "\n",
      "\"ecc.errors.corrected.aggregate.register_file\"\n",
      "Errors detected in register file memory.\n",
      "\n",
      "\"ecc.errors.corrected.aggregate.l1_cache\"\n",
      "Errors detected in the L1 cache.\n",
      "\n",
      "\"ecc.errors.corrected.aggregate.l2_cache\"\n",
      "Errors detected in the L2 cache.\n",
      "\n",
      "\"ecc.errors.corrected.aggregate.texture_memory\"\n",
      "Parity errors detected in texture memory.\n",
      "\n",
      "\"ecc.errors.corrected.aggregate.cbu\"\n",
      "Parity errors detected in CBU.\n",
      "\n",
      "\"ecc.errors.corrected.aggregate.sram\"\n",
      "Errors detected in global SRAMs.\n",
      "\n",
      "\"ecc.errors.corrected.aggregate.total\"\n",
      "Total errors detected across entire chip.\n",
      "\n",
      "\"ecc.errors.uncorrected.volatile.device_memory\"\n",
      "Errors detected in global device memory.\n",
      "\n",
      "\"ecc.errors.uncorrected.volatile.dram\"\n",
      "Errors detected in global device memory.\n",
      "\n",
      "\"ecc.errors.uncorrected.volatile.register_file\"\n",
      "Errors detected in register file memory.\n",
      "\n",
      "\"ecc.errors.uncorrected.volatile.l1_cache\"\n",
      "Errors detected in the L1 cache.\n",
      "\n",
      "\"ecc.errors.uncorrected.volatile.l2_cache\"\n",
      "Errors detected in the L2 cache.\n",
      "\n",
      "\"ecc.errors.uncorrected.volatile.texture_memory\"\n",
      "Parity errors detected in texture memory.\n",
      "\n",
      "\"ecc.errors.uncorrected.volatile.cbu\"\n",
      "Parity errors detected in CBU.\n",
      "\n",
      "\"ecc.errors.uncorrected.volatile.sram\"\n",
      "Errors detected in global SRAMs.\n",
      "\n",
      "\"ecc.errors.uncorrected.volatile.total\"\n",
      "Total errors detected across entire chip.\n",
      "\n",
      "\"ecc.errors.uncorrected.aggregate.device_memory\"\n",
      "Errors detected in global device memory.\n",
      "\n",
      "\"ecc.errors.uncorrected.aggregate.dram\"\n",
      "Errors detected in global device memory.\n",
      "\n",
      "\"ecc.errors.uncorrected.aggregate.register_file\"\n",
      "Errors detected in register file memory.\n",
      "\n",
      "\"ecc.errors.uncorrected.aggregate.l1_cache\"\n",
      "Errors detected in the L1 cache.\n",
      "\n",
      "\"ecc.errors.uncorrected.aggregate.l2_cache\"\n",
      "Errors detected in the L2 cache.\n",
      "\n",
      "\"ecc.errors.uncorrected.aggregate.texture_memory\"\n",
      "Parity errors detected in texture memory.\n",
      "\n",
      "\"ecc.errors.uncorrected.aggregate.cbu\"\n",
      "Parity errors detected in CBU.\n",
      "\n",
      "\"ecc.errors.uncorrected.aggregate.sram\"\n",
      "Errors detected in global SRAMs.\n",
      "\n",
      "\"ecc.errors.uncorrected.aggregate.total\"\n",
      "Total errors detected across entire chip.\n",
      "\n",
      "Section about retired_pages properties\n",
      "NVIDIA GPUs can retire pages of GPU device memory when they become unreliable. This can happen when multiple single bit ECC errors occur for the same page, or on a double bit ECC error. When a page is retired, the NVIDIA driver will hide it such that no driver, or application memory allocations can access it.\n",
      "\n",
      "\"retired_pages.single_bit_ecc.count\" or \"retired_pages.sbe\"\n",
      "The number of GPU device memory pages that have been retired due to multiple single bit ECC errors.\n",
      "\n",
      "\"retired_pages.double_bit.count\" or \"retired_pages.dbe\"\n",
      "The number of GPU device memory pages that have been retired due to a double bit ECC error.\n",
      "\n",
      "\"retired_pages.pending\"\n",
      "Checks if any GPU device memory pages are pending retirement on the next reboot. Pages that are pending retirement can still be allocated, and may cause further reliability issues.\n",
      "\n",
      "\"temperature.gpu\"\n",
      " Core GPU temperature. in degrees C.\n",
      "\n",
      "\"temperature.gpu.tlimit\"\n",
      " GPU T.Limit temperature. in degrees C.\n",
      "\n",
      "\"temperature.memory\"\n",
      " HBM memory temperature. in degrees C.\n",
      "\n",
      "\"power.management\"\n",
      "A flag that indicates whether power management is enabled. Either \"Supported\" or \"[Not Supported]\". Requires Inforom PWR object version 3.0 or higher or Kepler device.\n",
      "\n",
      "\"power.draw\"\n",
      "The last measured power draw for the entire board, in watts. On Ampere or newer devices, returns average power draw over 1 sec. On older devices, returns instantaneous power draw. Only available if power management is supported. This reading is accurate to within +/- 5 watts.\n",
      "\n",
      "\"power.draw.average\"\n",
      "The last measured average power draw for the entire board, in watts. Only available if power management is supported and Ampere (except GA100) or newer devices. This reading is accurate to within +/- 5 watts.\n",
      "\n",
      "\"power.draw.instant\"\n",
      "The last measured instant power draw for the entire board, in watts. Only available if power management is supported. This reading is accurate to within +/- 5 watts.\n",
      "\n",
      "\"power.limit\"\n",
      "The software power limit in watts. Set by software like nvidia-smi. On Kepler devices Power Limit can be adjusted using [-pl | --power-limit=] switches.\n",
      "\n",
      "\"enforced.power.limit\"\n",
      "The power management algorithm's power ceiling, in watts. Total board power draw is manipulated by the power management algorithm such that it stays under this value. This value is the minimum of various power limiters.\n",
      "\n",
      "\"power.default_limit\"\n",
      "The default power management algorithm's power ceiling, in watts. Power Limit will be set back to Default Power Limit after driver unload.\n",
      "\n",
      "\"power.min_limit\"\n",
      "The minimum value in watts that power limit can be set to.\n",
      "\n",
      "\"power.max_limit\"\n",
      "The maximum value in watts that power limit can be set to.\n",
      "\n",
      "\"clocks.current.graphics\" or \"clocks.gr\"\n",
      "Current frequency of graphics (shader) clock.\n",
      "\n",
      "\"clocks.current.sm\" or \"clocks.sm\"\n",
      "Current frequency of SM (Streaming Multiprocessor) clock.\n",
      "\n",
      "\"clocks.current.memory\" or \"clocks.mem\"\n",
      "Current frequency of memory clock.\n",
      "\n",
      "\"clocks.current.video\" or \"clocks.video\"\n",
      "Current frequency of video encoder/decoder clock.\n",
      "\n",
      "Section about clocks.applications properties\n",
      "User specified frequency at which applications will be running at. Can be changed with [-ac | --applications-clocks] switches.\n",
      "\n",
      "\"clocks.applications.graphics\" or \"clocks.applications.gr\"\n",
      "User specified frequency of graphics (shader) clock.\n",
      "\n",
      "\"clocks.applications.memory\" or \"clocks.applications.mem\"\n",
      "User specified frequency of memory clock.\n",
      "\n",
      "Section about clocks.default_applications properties\n",
      "Default frequency at which applications will be running at. Application clocks can be changed with [-ac | --applications-clocks] switches. Application clocks can be set to default using [-rac | --reset-applications-clocks] switches.\n",
      "\n",
      "\"clocks.default_applications.graphics\" or \"clocks.default_applications.gr\"\n",
      "Default frequency of applications graphics (shader) clock.\n",
      "\n",
      "\"clocks.default_applications.memory\" or \"clocks.default_applications.mem\"\n",
      "Default frequency of applications memory clock.\n",
      "\n",
      "Section about clocks.max properties\n",
      "Maximum frequency at which parts of the GPU are design to run.\n",
      "\n",
      "\"clocks.max.graphics\" or \"clocks.max.gr\"\n",
      "Maximum frequency of graphics (shader) clock.\n",
      "\n",
      "\"clocks.max.sm\" or \"clocks.max.sm\"\n",
      "Maximum frequency of SM (Streaming Multiprocessor) clock.\n",
      "\n",
      "\"clocks.max.memory\" or \"clocks.max.mem\"\n",
      "Maximum frequency of memory clock.\n",
      "\n",
      "Section about mig.mode properties\n",
      "A flag that indicates whether MIG mode is enabled. May be either \"Enabled\" or \"Disabled\". Changes to MIG mode require a GPU reset.\n",
      "\n",
      "\"mig.mode.current\"\n",
      "The MIG mode that the GPU is currently operating under.\n",
      "\n",
      "\"mig.mode.pending\"\n",
      "The MIG mode that the GPU will operate under after reset.\n",
      "\n",
      "Section about gsp.mode properties\n",
      "A flag that indicates whether GSP firmware is enabled.May be either \"Enabled\" or \"Disabled\".\n",
      "\n",
      "\"gsp.mode.current\"\n",
      "The current status of GSP firmware.\n",
      "\n",
      "\"gsp.mode.default\"\n",
      "The default status of GSP firmware.\n",
      "\n",
      "Section about protected_memory properties\n",
      "On-board protected memory information.\n",
      "\n",
      "\"protected_memory.total\"\n",
      "Total installed GPU conf compute protected memory.\n",
      "\n",
      "\"protected_memory.used\"\n",
      "Total conf compute protected memory allocated by active contexts.\n",
      "\n",
      "\"protected_memory.free\"\n",
      "Total free conf compute protected memory.\n",
      "\n",
      "\"fabric.state\"\n",
      "Current state of GPU fabric registration process.\n",
      "\n",
      "\"fabric.status\"\n",
      "Error status, valid only if gpu fabric registration state is \"completed\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://nvidia.custhelp.com/app/answers/detail/a_id/3751/~/useful-nvidia-smi-queries\n",
    "# > You can get a complete list of the query arguments by issuing: nvidia-smi --help-query-gpu\n",
    "nvidia-smi --help-query-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index, count, timestamp, name, utilization.gpu [%], utilization.memory [%], memory.total [MiB], memory.free [MiB], memory.used [MiB]\n",
      "0, 1, 2024/08/04 11:31:31.017, NVIDIA GeForce RTX 4090, 0, 0, 24564, 24216, 1\n"
     ]
    }
   ],
   "source": [
    "nvidia-smi --query-gpu=index,count,timestamp,name,utilization.gpu,utilization.memory,memory.total,memory.free,memory.used --format=csv,nounits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
